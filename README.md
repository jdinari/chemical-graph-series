# ğŸ§ª Chemical Graph Series

A progressive educational journey from basic **cheminformatics** to state-of-the-art **Graph Neural Networks (GNNs)** and **Molecular Transformers**. This series covers everything from representing molecules as graphs to predicting chemical properties using advanced deep learning architectures.

![Molecular Graph Representation](molGraph.png)

---

## ğŸ¯ Who Is This For?

This series is designed for:

- **Computational chemists** looking to apply deep learning to molecular data
- **ML engineers** interested in graph neural networks with a chemistry application
- **Drug discovery researchers** wanting to build property prediction models
- **Students** with basic Python and chemistry knowledge

**Prerequisites**: Basic Python (loops, functions, data structures) and fundamental chemistry (molecular structure, bonds, functional groups). No prior experience with RDKit, graph theory, or deep learning requiredâ€”we teach everything from scratch.

---

## ğŸš€ Curriculum Overview

The course is structured into 7 sequential notebooks, progressively building from foundations to production-ready models.

| Lesson | Title | Key Concepts | Time |
| :--- | :--- | :--- | :---: |
| **01** | [Building Graphs](./notebooks/01_Building_Graphs.ipynb) | SMILES parsing, RDKit, Mol-to-Graph, Feature extraction | 45-60 min |
| **02** | [Positional Encoding](./notebooks/02_Positional_Encoding.ipynb) | Laplacian Eigenvectors, RWPE, Spectral Analysis | 60-75 min |
| **03** | [GAT Model](./notebooks/03_GAT_Model.ipynb) | Graph Attention Networks, Message Passing, Multi-head Attention | 75-90 min |
| **04** | [Sparse Attention](./notebooks/04_Sparse%20Attention.ipynb) | Efficiency in Graph Transformers, Virtual Edges, Locality | 60-75 min |
| **05** | [Full Graph Transformer](./notebooks/05_Full_Graph_Transformer.ipynb) | Global Self-Attention, Edge Features, Deep Architectures | 90-105 min |
| **06** | [Advanced Graph Models](./notebooks/06_Advanced_Graph_Models.ipynb) | GraphGPS, E(3)-GNNs, Equivariance, Hybrid Architectures | 90-105 min |
| **07** | [Modelling & Predictions](./notebooks/07_Modelling_and_Predictions.ipynb) | Property Prediction (ESOL, FreeSolv), Training Pipelines | 120-150 min |

**Total Estimated Time**: ~9-11 hours

---

## ğŸ“š Learning Path

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FOUNDATIONS (Lessons 01-02)                      â”‚
â”‚  â€¢ Molecular representations    â€¢ Feature extraction                   â”‚
â”‚  â€¢ Graph structures             â€¢ Positional encodings                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ATTENTION MECHANISMS (Lessons 03-04)               â”‚
â”‚  â€¢ Local attention (GAT)        â€¢ Sparse patterns                      â”‚
â”‚  â€¢ Message passing              â€¢ Scalability                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ADVANCED ARCHITECTURES (Lessons 05-06)               â”‚
â”‚  â€¢ Graph Transformers           â€¢ GraphGPS                             â”‚
â”‚  â€¢ Global context               â€¢ Equivariant networks                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         APPLICATION (Lesson 07)                         â”‚
â”‚  â€¢ Real datasets (ESOL, FreeSolv)    â€¢ Model comparison                â”‚
â”‚  â€¢ Training pipelines                â€¢ Deployment                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Setup & Installation

This project uses `pyproject.toml` for dependency management. It is recommended to use [uv](https://github.com/astral-sh/uv) for fast, reliable package management.

### Using `uv` (Recommended)

```bash
# Clone the repository
git clone https://github.com/yourusername/ChemicalGraphSeries.git
cd ChemicalGraphSeries

# Sync environment and install all dependencies
uv sync

# Launch Jupyter
uv run jupyter notebook
```

### Using `pip`

```bash
# Create a virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install rdkit torch torch-geometric networkx matplotlib pandas jupyter py3dmol scipy

# Launch Jupyter
jupyter notebook
```

### Verify Installation

```python
# Run this in a notebook cell to verify everything works
from rdkit import Chem
import torch
import torch_geometric
import networkx as nx

print(f"RDKit: {Chem.rdBase.rdkitVersion}")
print(f"PyTorch: {torch.__version__}")
print(f"PyTorch Geometric: {torch_geometric.__version__}")
print("âœ… All dependencies installed successfully!")
```

---

## ğŸ“‚ Project Structure

```
ChemicalGraphSeries/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_Building_Graphs.ipynb      # Foundations: SMILES, RDKit, graphs
â”‚   â”œâ”€â”€ 02_Positional_Encoding.ipynb  # Spectral graph theory & RWPE
â”‚   â”œâ”€â”€ 03_GAT_Model.ipynb            # Graph Attention Networks
â”‚   â”œâ”€â”€ 04_Sparse Attention.ipynb     # Efficient attention patterns
â”‚   â”œâ”€â”€ 05_Full_Graph_Transformer.ipynb  # Complete transformer architecture
â”‚   â”œâ”€â”€ 06_Advanced_Graph_Models.ipynb   # GraphGPS, E(3)-GNNs
â”‚   â””â”€â”€ 07_Modelling_and_Predictions.ipynb  # Real-world applications
â”œâ”€â”€ molGraph.png                      # Visual for documentation
â”œâ”€â”€ pyproject.toml                    # Project dependencies
â”œâ”€â”€ uv.lock                           # Locked dependency versions
â”œâ”€â”€ main.py                           # Utility scripts
â””â”€â”€ README.md                         # This file
```

---

## ğŸ§ª Requirements

| Requirement | Version |
|-------------|---------|
| **Python** | â‰¥ 3.13 |
| **RDKit** | latest |
| **PyTorch** | latest |
| **PyTorch Geometric** | latest |
| **NetworkX** | latest |
| **matplotlib** | latest |
| **pandas** | latest |
| **py3Dmol** | â‰¥ 2.5.3 |
| **scipy** | â‰¥ 1.16.3 |

---

## ğŸ“ What You'll Build

By the end of this series, you will have:

1. **Molecular featurization pipelines** â€” Convert any SMILES string into ML-ready graph representations
2. **Custom GNN architectures** â€” GATs, Graph Transformers, and hybrid models
3. **Property prediction models** â€” Trained on ESOL (solubility) and FreeSolv (solvation energy) benchmarks
4. **Interpretable AI** â€” Visualize attention weights to understand what your model "sees"
5. **Production-ready code** â€” Deployable models for real-world molecular property prediction

---

## ğŸ“– Key Topics Covered

### Cheminformatics
- SMILES and SMARTS notation
- Molecular visualization (2D, 3D, conformer ensembles)
- Substructure matching and pharmacophore identification

### Graph Theory
- Molecules as graphs (atoms = nodes, bonds = edges)
- Adjacency and Laplacian matrices
- Spectral graph theory and eigenvector decomposition

### Deep Learning
- Message passing neural networks
- Attention mechanisms (single-head, multi-head, sparse)
- Transformer architectures adapted for graphs
- Equivariant neural networks (E(3)-GNNs)

### Practical ML
- Feature engineering for molecular properties
- Train/validation/test splitting with scaffold awareness
- Hyperparameter tuning and cross-validation
- Model interpretation and error analysis

---

## ğŸ”— Resources & Further Reading

**RDKit Documentation**: https://www.rdkit.org/docs/  
**PyTorch Geometric**: https://pytorch-geometric.readthedocs.io/  
**DeepChem**: https://deepchem.io/  
**OGB Molecular Benchmarks**: https://ogb.stanford.edu/

**Key Papers**:
- VeliÄkoviÄ‡ et al. (2018) â€” Graph Attention Networks
- RampÃ¡Å¡ek et al. (2022) â€” GraphGPS
- Dwivedi et al. (2021) â€” Benchmarking GNNs

---

## ğŸ“ License

This project is for educational purposes. Feel free to use, modify, and share with attribution.

---

<p align="center">
  <strong>Ready to start?</strong> Open <a href="./notebooks/01_Building_Graphs.ipynb">Lesson 01: Building Graphs</a> and begin your journey!
</p>
